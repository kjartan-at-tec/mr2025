% Created 2021-11-16 Tue 07:28
% Intended LaTeX compiler: pdflatex
\documentclass[presentation,aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{khpreamble}
\usepackage{amssymb}
\usepackage{pgfplotstable}
\DeclareMathOperator{\shift}{q}
\DeclareMathOperator{\diff}{p}
\usetheme{default}
\author{Kjartan Halvorsen}
\date{\today}
\title{System identification}
\hypersetup{
 pdfauthor={Kjartan Halvorsen},
 pdftitle={System identification},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.4.6)}, 
 pdflang={English}}
\begin{document}

\maketitle

\section{Intro}
\label{sec:org11c96cd}
\begin{frame}[label={sec:org0994cac}]{A complicated process}
\begin{columns}
\begin{column}{0.6\columnwidth}
From Wikipedia "Cyclonic separation"
\end{column}
\begin{column}{0.4\columnwidth}
\begin{center}
\includegraphics[height=1.0\textheight]{../../figures/Vertical-cyclone.jpg}
\end{center}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:orgcf1505b}]{System identification}
\small

\begin{center}
  \begin{tikzpicture}[node distance=22mm, block/.style={rectangle, draw, minimum width=15mm, inner sep=10pt}, sumnode/.style={circle, draw, inner sep=2pt},]

    \node[coordinate] (input) {};
    \node[coordinate, right of=input] (copy) {};
    \node[coordinate, right of=copy] (midp) {};
    \node[block, above of=midp, node distance=10mm] (sys)  {System};
    \node[block, below of=midp, node distance=10mm] (mod)  {Model};
    \node[sumnode, right of=midp, node distance=26mm] (sum) {\tiny $\Sigma$};
    \node[coordinate, right of=sum, node distance=22mm] (output) {};

    \draw[-] (input) -- node[above, pos=0.2] {\tiny Measured input} (copy);
    \draw[->] (copy) |- node[above] {} (sys);
    \draw[->] (copy) |- node[above] {} (mod);
    \draw[->] (sys) -| node[above, pos=0.4] {\tiny Measured output} node[left, pos=0.9] {$+$} (sum);
    \draw[->] (mod) -| node[below, pos=0.4] {\tiny Predicted output} node[left, pos=0.9] {$-$} (sum);
    \draw[->] (sum) -- node[above, near end] {\tiny Error} (output);

    \draw[thick, red!70!black, ->] (2.7,-2) -- (3.3,-2) -- (5.3, 0);
  \end{tikzpicture}
\end{center}
\end{frame}

\begin{frame}[label={sec:org865b102}]{The shift operator \(\shift\)}
\[ \shift x(k) = x(k+1), \qquad \shift^{-1}x(k) = x(k-1) \]

\pause

\begin{description}
\item[{Domain and codomain}] Double-infinite sequences \(x(k)\), i.e. \(-\infty < k < \infty\)
\item[{Operation}] \(\shift\) shifts the sequence ahead one step, \(\shift^{-1}\) shifts the sequence back one step
\end{description}

\pause

\begin{block}{Algebra with the shift operator}
\[ \frac{\shift - \shift^{-1}}{2h} x(k) = \frac{1}{2h}\left( \shift x(k) - \shift^{-1}x(k)\right) = ? \]

\pause

\[ \qquad = \frac{x(k+1) - x(k-1)}{2h} \]
\end{block}
\end{frame}


\begin{frame}[label={sec:org7b8b4ba}]{The Auto-Regressive with eXogenous input (ARX) model}
\begin{center}
\includegraphics[width=0.7\linewidth]{../../figures/block-arx}
\end{center}
\[ A(\shift) y(k) = B(\shift)u(k) + e(k+n) \]

The error signal \(e(k)\) is a zero-mean white noise sequence representing perturbations and modeling errors.
\end{frame}

\begin{frame}[label={sec:orgcdc2333}]{First-order ARX model with one delay}
\small

\begin{center}
\includegraphics[width=0.3\linewidth]{../../figures/block-arx}
\end{center}
\[ (\shift + a_1) y(k) = (b_0 \shift + b_1) \shift^{-1}u(k) + e(k+1) \]
\pause
\[ y(k+1) +  a_1y(k) = b_0u(k) + b_1u(k-1) + e(k+1) \]
\pause
\[ y(k+1) = \textcolor{white}{-a_1y(k) + b_0u(k) + b_1u(k-1) e(k+1)} \]
\pause

\[ y(k+1) = \textcolor{black}{-a_1y(k) + b_0u(k) + b_1u(k-1) e(k+1)} \]

Using the model to predict the output one step ahead:
\begin{align*}
 \hat{y}(k+1) &= -a_1y(k) + b_0u(k) + b_1u(k-1) =  \underbrace{\begin{bmatrix} -y(k) & u(k) & u(k-1) \end{bmatrix}}_{\varphi_{k+1}^T} \underbrace{\begin{bmatrix} a_1\\b_0\\b_1\end{bmatrix}}_{\theta}\\
 &= \varphi_{k+1}^T\theta
 \end{align*}
\end{frame}



\begin{frame}[label={sec:orgefa5ea5}]{Parameter estimation - Least squares}
\alert{Objective} Given observations \[\mathcal{D} = \{ (u_1,y_1), (u_2, y_2), \ldots, (u_N, y_N)\}\] and model \(\mathcal{M}: \; y(k+1) = -ay(k) + b_0u(k) + b_1u(k-1)  + e(k+1)\), obtain the parameters \((a_1,\,b_0,\,b_1)\) which gives the best fit of the model to the data.
\end{frame}



\begin{frame}[label={sec:org8585052}]{Parameter estimation - Least squares}
Given observations \[\mathcal{D} = \{ (u_1,y_1), (u_2, y_2), \ldots, (u_N, y_N)\}\] and model \(\mathcal{M}: \; y(k+1) = -ay(k) + b_0u(k) + b_1u(k-1)  + e(k+1)\).

\begin{enumerate}
\item Form the one-step ahead prediction
\[ \hat{y}_{k+1} = -a_1y_k + b_0u_k + b_1u_{k-1} =  \underbrace{\begin{bmatrix} -y_k & u_k & u_{k-1} \end{bmatrix}}_{\varphi_{k+1}^T} \underbrace{\begin{bmatrix} a_1\\b_0\\b_1\end{bmatrix}}_{\theta}\] and the prediction error
   \[ \epsilon_{k+1} = y_{k+1} - \hat{y}_{k+1} = y_{k+1} - \varphi_{k+1}^T\theta.\]
\end{enumerate}
\end{frame}


\begin{frame}[label={sec:org7e6a9f6}]{Parameter estimation - Least squares}
\begin{enumerate}
\setcounter{enumi}{1}
\item Combine all the observations \(y_k\) and predictions \(\hat{y}_k\) on vector form
\begin{align*}
\epsilon &= \begin{bmatrix} \epsilon_3\\\epsilon_4\\\vdots\\\epsilon_N\end{bmatrix} =  \begin{bmatrix} y_3\\ y_4\\\vdots\\y_N \end{bmatrix} - \begin{bmatrix} \hat{y}_3\\ \hat{y}_4\\\vdots\\\hat{y}_N \end{bmatrix}
 =  \begin{bmatrix} y_2\\ y_3\\\vdots\\y_N \end{bmatrix} - \begin{bmatrix} \varphi_2^T\theta\\ \varphi_3^T\theta\\\vdots\\\varphi_N^T\theta \end{bmatrix}\\
&= y - \underbrace{\begin{bmatrix}\varphi_1^T\\\varphi_2^T\\\vdots\\\varphi_N^T\end{bmatrix}}_{\Phi}\theta = y - \Phi\theta 
\end{align*}
\item Solve \(\arg\min \; J(\theta) = \frac{1}{2}\epsilon^T\epsilon = \frac{1}{2}\sum_{i=3}^N \epsilon_i(\theta)^2\) \(\quad \Rightarrow \hat{\theta}_{LS} = (\Phi^T\Phi)^{-1}\Phi^Ty\)
\end{enumerate}
\end{frame}


\begin{frame}[label={sec:orgb3ee24f}]{The problem with least squares}
\begin{columns}
\begin{column}{0.4\columnwidth}
\begin{align*}
 \text{minimize} \; &\sum_k g(\epsilon_k)\\
 \text{where} \; g(u) &= u^2
\end{align*}
\end{column}

\begin{column}{0.6\columnwidth}
\begin{center}
  \begin{tikzpicture}
    \begin{axis}[
      width=8cm,
      height=6cm,
      ylabel=loss,
      xlabel=penalty,
      ]
      \addplot[red, thick, no marks, domain=-4:4, samples=201] {x^2};
    \end{axis}
  \end{tikzpicture}
\end{center}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:org10fbc71}]{More robust: The Huber loss function}
\begin{columns}
\begin{column}{0.4\columnwidth}
Also known as \alert{robust regression}
\begin{align*}
 \text{minimize} \; &\sum_k g_{hub}(\epsilon_k)\\
 \text{where}\; g_{hub}(u) &= \begin{cases} u^2 & |u| \le M\\ M(2|u|-M) & |u| > M \end{cases}
\end{align*}
\end{column}

\begin{column}{0.6\columnwidth}
\begin{center}
  \begin{tikzpicture}
    \begin{axis}[
      width=8cm,
      height=6cm,
      ylabel=penalty,
      xlabel=residual,
      ]
      \addplot[red, thick, no marks, domain=-4:4, samples=201] {x^2};
      \addplot[orange!90!black, ultra thick, no marks, domain=-4:-1, samples=201] {2*abs(x)-1};
      \addplot[orange!90!black, thin, no marks, domain=-1:1, samples=201] {x^2};
      \addplot[orange!90!black, ultra thick, no marks, domain=1:4, samples=201] {2*abs(x)-1};
    \end{axis}
  \end{tikzpicture}
\end{center}
\end{column}
\end{columns}
\end{frame}


\begin{frame}[label={sec:org81b4333}]{First-order ARX model without delay}
\begin{center}
\includegraphics[width=0.4\linewidth]{../../figures/block-arx}
\end{center}
\[ (\shift + a_1) y(k) = (b_0 \shift + b_1) u(k) + e(k+1) \]

\alert{Activity}

\begin{enumerate}
\item Determine the one-step ahead predictor \(\hat{y}_{k+1}\) and the prediction error \(\epsilon_{k+1}\).
\item Form the system of equations \(\Phi\theta = y\)
\end{enumerate}
\end{frame}


\begin{frame}[label={sec:org9016e88}]{The ARX model}
\[ A(\shift) y(k) = B(\shift)u(k) + e(k+n)\]

\alert{Activity} Fill the empty blocks.

\begin{center}
  \begin{tikzpicture}[node distance=22mm, block/.style={rectangle, draw, minimum width=15mm, minimum height=12mm}, sumnode/.style={circle, draw, inner sep=2pt}]
    
    \node[coordinate] (input) {};
    \node[block, right of=input, node distance=20mm] (plant)  {};
    \node[sumnode, right of=plant, node distance=24mm] (sum) {\tiny $\Sigma$};
    \node[block, above of=sum, node distance=20mm] (dist)  {};

    \node[coordinate, above of=dist, node distance=12mm] (disturbance) {};
    \node[coordinate, right of=sum, node distance=20mm] (output) {};

    \draw[->] (input) -- node[above, pos=0.3] {$u(k)$} (plant);
    \draw[->] (plant) -- node[above] {} (sum);
    \draw[->] (sum) -- node[above, near end] {$y(k)$} (output);
    \draw[->] (disturbance) -- node[right, pos=0.2] {$e(k)$} (dist);
    \draw[->] (dist) -- node[above] {} (sum);

  \end{tikzpicture}
\end{center}
\end{frame}
\end{document}